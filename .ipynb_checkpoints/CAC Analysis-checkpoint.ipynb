{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve,\\\n",
    "davies_bouldin_score as dbs, normalized_mutual_info_score as nmi\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import umap\n",
    "import sys\n",
    "\n",
    "from CAC import CAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = [\"magic\", \"diabetes\"]\n",
    "classifier = ['LR', 'Perceptron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(DATASET):\n",
    "\tif DATASET == \"cic\":\n",
    "\t    Xa = pd.read_csv(\"./data/CIC/cic_set_a.csv\")\n",
    "\t    Xb = pd.read_csv(\"./data/CIC/cic_set_b.csv\")\n",
    "\t    Xc = pd.read_csv(\"./data/CIC/cic_set_c.csv\")\n",
    "\n",
    "\t    ya = Xa['In-hospital_death']\n",
    "\t    yb = Xb['In-hospital_death']\n",
    "\t    yc = Xc['In-hospital_death']\n",
    "\n",
    "\t    Xa = Xa.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "\t    Xb = Xb.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "\t    Xc = Xc.drop(columns=['recordid', 'Survival', 'In-hospital_death'])\n",
    "\n",
    "\t    cols = Xa.columns\n",
    "\n",
    "\t    scale = StandardScaler()\n",
    "\t    Xa = scale.fit_transform(Xa)\n",
    "\t    Xb = scale.fit_transform(Xb)\n",
    "\t    Xc = scale.fit_transform(Xc)\n",
    "\n",
    "\t    Xa = pd.DataFrame(Xa, columns=cols)\n",
    "\t    Xb = pd.DataFrame(Xb, columns=cols)\n",
    "\t    Xc = pd.DataFrame(Xc, columns=cols)\n",
    "\n",
    "\t    Xa = Xa.fillna(0)\n",
    "\t    Xb = Xb.fillna(0)\n",
    "\t    Xc = Xc.fillna(0)\n",
    "\n",
    "\t    X_train = pd.concat([Xa, Xb])\n",
    "\t    y_train = pd.concat([ya, yb])\n",
    "\n",
    "\t    X_test = Xc\n",
    "\t    y_test = yc\n",
    "\n",
    "\t    X = pd.concat([X_train, X_test]).to_numpy()\n",
    "\t    y = pd.concat([y_train, y_test]).to_numpy()\n",
    "\n",
    "\telif DATASET == \"titanic\":\n",
    "\t    X_train = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"X_train.csv\").to_numpy()\n",
    "\t    X_test = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"X_test.csv\").to_numpy()\n",
    "\t    y_train = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"y_train.csv\").to_numpy()\n",
    "\t    y_test = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"y_test.csv\").to_numpy()\n",
    "\n",
    "\t    X = np.vstack([X_train, X_test])\n",
    "\t    y = np.vstack([y_train, y_test])\n",
    "\t    # X = pd.concat([X_train, X_test]).to_numpy()\n",
    "\t    # y = pd.concat([y_train, y_test]).to_numpy()\n",
    "\n",
    "\telse:\n",
    "\t    X = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"X.csv\").to_numpy()\n",
    "\t    y = pd.read_csv(\"./data/\" + DATASET + \"/\" + \"y.csv\").to_numpy()\n",
    "\n",
    "\treturn X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6000cf783717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m108\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X, y = get_dataset(DATASET[1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=108) \n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train) \n",
    "X_test = scale.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
